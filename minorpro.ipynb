{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 10705,
          "sourceType": "datasetVersion",
          "datasetId": 7160
        }
      ],
      "dockerImageVersionId": 30886,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import loadmat\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-02T05:36:03.660933Z",
          "iopub.execute_input": "2025-04-02T05:36:03.661273Z",
          "iopub.status.idle": "2025-04-02T05:36:04.283192Z",
          "shell.execute_reply.started": "2025-04-02T05:36:03.661244Z",
          "shell.execute_reply": "2025-04-02T05:36:04.281889Z"
        },
        "id": "3t1rbOLxEhoI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"crawford/emnist\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "ylrfbZbAEl5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emnist = pd.read_csv(\"/root/.cache/kagglehub/datasets/crawford/emnist/versions/3/emnist-balanced-train.csv\")\n",
        "emnist_test = pd.read_csv(\"/root/.cache/kagglehub/datasets/crawford/emnist/versions/3/emnist-balanced-test.csv\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-02T05:36:04.584286Z",
          "iopub.execute_input": "2025-04-02T05:36:04.584831Z",
          "iopub.status.idle": "2025-04-02T05:36:16.751898Z",
          "shell.execute_reply.started": "2025-04-02T05:36:04.584794Z",
          "shell.execute_reply": "2025-04-02T05:36:16.750965Z"
        },
        "id": "X4vCdNWlEhoL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = emnist.iloc[:, 0].values  # First column contains labels\n",
        "train_images = emnist.iloc[:, 1:].values  # Remaining columns contain pixel values\n",
        "\n",
        "# Extract labels and images for test data\n",
        "test_labels = emnist_test.iloc[:, 0].values  # First column contains labels\n",
        "test_images = emnist_test.iloc[:, 1:].values  # Remaining columns contain pixel values"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-02T05:36:16.753111Z",
          "iopub.execute_input": "2025-04-02T05:36:16.753405Z",
          "iopub.status.idle": "2025-04-02T05:36:16.758956Z",
          "shell.execute_reply.started": "2025-04-02T05:36:16.753377Z",
          "shell.execute_reply": "2025-04-02T05:36:16.757798Z"
        },
        "id": "313Uc1E0EhoL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Unique labels in training data:\", np.unique(train_labels))\n",
        "print(\"Unique labels in test data:\", np.unique(test_labels))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-02T05:36:16.760931Z",
          "iopub.execute_input": "2025-04-02T05:36:16.761214Z",
          "iopub.status.idle": "2025-04-02T05:36:16.786852Z",
          "shell.execute_reply.started": "2025-04-02T05:36:16.761188Z",
          "shell.execute_reply": "2025-04-02T05:36:16.785445Z"
        },
        "id": "Dp_WF1kQEhoM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Normalize pixel values (0 to 1 range)\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# **✅ Reshape the images to (28, 28, 1) instead of (784, 1, 1)**\n",
        "train_images = train_images.reshape(-1, 28, 28, 1)\n",
        "test_images = test_images.reshape(-1, 28, 28, 1)\n",
        "\n",
        "num_classes = np.max(train_labels) + 1  # This will be 47\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "train_labels = to_categorical(train_labels, num_classes)\n",
        "test_labels = to_categorical(test_labels, num_classes)\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "\n",
        "num_classes = 47  # Number of character classes\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),  # Prevent overfitting\n",
        "    Dense(num_classes, activation='softmax')  # Ensure 47 output classes\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-02T05:36:16.788361Z",
          "iopub.execute_input": "2025-04-02T05:36:16.788758Z",
          "iopub.status.idle": "2025-04-02T05:36:37.751533Z",
          "shell.execute_reply.started": "2025-04-02T05:36:16.788723Z",
          "shell.execute_reply": "2025-04-02T05:36:37.750337Z"
        },
        "id": "XKMXKeuMEhoM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_images, train_labels, epochs=30, batch_size=32, validation_data=(test_images, test_labels))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-02T05:36:37.752978Z",
          "iopub.execute_input": "2025-04-02T05:36:37.753765Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UPmLdmHEhoN",
        "outputId": "29f7fffd-67fa-4a79-e959-3875e975838b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 7ms/step - accuracy: 0.5930 - loss: 1.4003 - val_accuracy: 0.8114 - val_loss: 0.5590\n",
            "Epoch 2/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - accuracy: 0.7978 - loss: 0.5959 - val_accuracy: 0.8302 - val_loss: 0.4862\n",
            "Epoch 3/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - accuracy: 0.8204 - loss: 0.5186 - val_accuracy: 0.8288 - val_loss: 0.4873\n",
            "Epoch 4/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - accuracy: 0.8328 - loss: 0.4779 - val_accuracy: 0.8488 - val_loss: 0.4404\n",
            "Epoch 5/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8429 - loss: 0.4442 - val_accuracy: 0.8500 - val_loss: 0.4368\n",
            "Epoch 6/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.8459 - loss: 0.4234 - val_accuracy: 0.8579 - val_loss: 0.4237\n",
            "Epoch 7/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - accuracy: 0.8526 - loss: 0.4057 - val_accuracy: 0.8514 - val_loss: 0.4362\n",
            "Epoch 8/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.8570 - loss: 0.3880 - val_accuracy: 0.8521 - val_loss: 0.4283\n",
            "Epoch 9/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 5ms/step - accuracy: 0.8631 - loss: 0.3747 - val_accuracy: 0.8552 - val_loss: 0.4330\n",
            "Epoch 10/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.8655 - loss: 0.3591 - val_accuracy: 0.8554 - val_loss: 0.4347\n",
            "Epoch 11/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.8685 - loss: 0.3493 - val_accuracy: 0.8553 - val_loss: 0.4298\n",
            "Epoch 12/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.8724 - loss: 0.3381 - val_accuracy: 0.8591 - val_loss: 0.4253\n",
            "Epoch 13/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8753 - loss: 0.3298 - val_accuracy: 0.8549 - val_loss: 0.4435\n",
            "Epoch 14/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.8769 - loss: 0.3205 - val_accuracy: 0.8600 - val_loss: 0.4312\n",
            "Epoch 15/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.8790 - loss: 0.3131 - val_accuracy: 0.8577 - val_loss: 0.4399\n",
            "Epoch 16/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8822 - loss: 0.3045 - val_accuracy: 0.8588 - val_loss: 0.4300\n",
            "Epoch 17/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.8856 - loss: 0.2961 - val_accuracy: 0.8605 - val_loss: 0.4518\n",
            "Epoch 18/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.8866 - loss: 0.2922 - val_accuracy: 0.8580 - val_loss: 0.4528\n",
            "Epoch 19/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.8873 - loss: 0.2864 - val_accuracy: 0.8579 - val_loss: 0.4717\n",
            "Epoch 20/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8896 - loss: 0.2823 - val_accuracy: 0.8575 - val_loss: 0.4554\n",
            "Epoch 21/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.8926 - loss: 0.2723 - val_accuracy: 0.8576 - val_loss: 0.4575\n",
            "Epoch 22/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - accuracy: 0.8930 - loss: 0.2694 - val_accuracy: 0.8564 - val_loss: 0.4726\n",
            "Epoch 23/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.8927 - loss: 0.2707 - val_accuracy: 0.8598 - val_loss: 0.4697\n",
            "Epoch 24/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - accuracy: 0.8972 - loss: 0.2586 - val_accuracy: 0.8544 - val_loss: 0.4906\n",
            "Epoch 25/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.8973 - loss: 0.2558 - val_accuracy: 0.8537 - val_loss: 0.4975\n",
            "Epoch 26/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.8988 - loss: 0.2543 - val_accuracy: 0.8577 - val_loss: 0.4812\n",
            "Epoch 27/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9014 - loss: 0.2467 - val_accuracy: 0.8575 - val_loss: 0.4868\n",
            "Epoch 28/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - accuracy: 0.9025 - loss: 0.2440 - val_accuracy: 0.8583 - val_loss: 0.5011\n",
            "Epoch 29/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.9032 - loss: 0.2407 - val_accuracy: 0.8559 - val_loss: 0.5048\n",
            "Epoch 30/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.9008 - loss: 0.2418 - val_accuracy: 0.8557 - val_loss: 0.5157\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7972f8c391d0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elK6Wsd0EhoO",
        "outputId": "c8a0df03-0a5e-4fee-ec8c-15d2cf8cdf5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m588/588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8531 - loss: 0.5172\n",
            "Test Accuracy: 0.8557\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Define the Wolf Optimization Algorithm (WOA)\n",
        "def woa_optimize(iterations=10, wolves=5):\n",
        "    best_lr = None\n",
        "    best_filters = None\n",
        "    best_accuracy = 0\n",
        "\n",
        "    learning_rates = np.random.uniform(0.0001, 0.01, wolves)\n",
        "    filters = np.random.choice([32, 64, 128], wolves)\n",
        "\n",
        "    for i in range(iterations):\n",
        "        for j in range(wolves):\n",
        "            model = Sequential([\n",
        "                Conv2D(filters[j], (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "                BatchNormalization(),\n",
        "                MaxPooling2D(2, 2),\n",
        "                Conv2D(64, (3, 3), activation='relu'),\n",
        "                BatchNormalization(),\n",
        "                MaxPooling2D(2, 2),\n",
        "                Flatten(),\n",
        "                Dense(256, activation='relu'),\n",
        "                Dropout(0.5),\n",
        "                Dense(num_classes, activation='softmax')\n",
        "            ])\n",
        "\n",
        "            model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rates[j]),\n",
        "                          loss='categorical_crossentropy',\n",
        "                          metrics=['accuracy'])\n",
        "\n",
        "            model.fit(train_images, train_labels, epochs=3, batch_size=32, verbose=0)\n",
        "            _, accuracy = model.evaluate(test_images, test_labels, verbose=0)\n",
        "\n",
        "            if accuracy > best_accuracy:\n",
        "                best_accuracy = accuracy\n",
        "                best_lr = learning_rates[j]\n",
        "                best_filters = filters[j]\n",
        "\n",
        "    print(f'Best Learning Rate: {best_lr}, Best Filters: {best_filters}, Best Accuracy: {best_accuracy}')\n",
        "    return best_lr, best_filters\n",
        "\n",
        "# Run WOA optimization\n",
        "best_lr, best_filters = woa_optimize()\n"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsvCAbcwEhoO",
        "outputId": "5dae0b8a-ded7-4f6c-d6d5-0a655f8174cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Learning Rate: 0.0007554813929312193, Best Filters: 64, Best Accuracy: 0.8732379674911499\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(params):\n",
        "    model = Sequential([\n",
        "        Conv2D(params['filters'], (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(params['dropout']),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params['learning_rate']),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Train model with best WOA parameters\n",
        "best_woa_params = {'filters': 64, 'dropout': 0.5, 'learning_rate': 0.0007554813929312193}\n",
        "best_woa_model = create_model(best_woa_params)\n",
        "best_woa_model.fit(train_images, train_labels, epochs=30, batch_size=32, verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKJYtjFrcxFB",
        "outputId": "0321974e-a522-47a9-9d31-2dd112bd8d9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - accuracy: 0.6148 - loss: 1.3771\n",
            "Epoch 2/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.8081 - loss: 0.5789\n",
            "Epoch 3/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.8348 - loss: 0.4888\n",
            "Epoch 4/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.8496 - loss: 0.4316\n",
            "Epoch 5/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.8604 - loss: 0.3895\n",
            "Epoch 6/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.8677 - loss: 0.3637\n",
            "Epoch 7/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.8747 - loss: 0.3422\n",
            "Epoch 8/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.8835 - loss: 0.3184\n",
            "Epoch 9/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.8889 - loss: 0.3030\n",
            "Epoch 10/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.8931 - loss: 0.2889\n",
            "Epoch 11/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.8964 - loss: 0.2766\n",
            "Epoch 12/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.9020 - loss: 0.2649\n",
            "Epoch 13/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.9051 - loss: 0.2509\n",
            "Epoch 14/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - accuracy: 0.9095 - loss: 0.2399\n",
            "Epoch 15/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9120 - loss: 0.2316\n",
            "Epoch 16/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9156 - loss: 0.2249\n",
            "Epoch 17/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9171 - loss: 0.2185\n",
            "Epoch 18/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.9203 - loss: 0.2056\n",
            "Epoch 19/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.9245 - loss: 0.2008\n",
            "Epoch 20/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9248 - loss: 0.2008\n",
            "Epoch 21/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.9261 - loss: 0.1949\n",
            "Epoch 22/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.9305 - loss: 0.1821\n",
            "Epoch 23/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9318 - loss: 0.1839\n",
            "Epoch 24/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9338 - loss: 0.1794\n",
            "Epoch 25/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9334 - loss: 0.1774\n",
            "Epoch 26/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.9384 - loss: 0.1682\n",
            "Epoch 27/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.9398 - loss: 0.1639\n",
            "Epoch 28/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.9393 - loss: 0.1634\n",
            "Epoch 29/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.9417 - loss: 0.1596\n",
            "Epoch 30/30\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.9403 - loss: 0.1578\n",
            "\u001b[1m588/588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8632 - loss: 0.7062\n",
            "Test Accuracy: 0.8636\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate final model\n",
        "test_loss, test_acc = best_woa_model.evaluate(test_images, test_labels, batch_size=1024)\n",
        "\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1icFTYoKl9lP",
        "outputId": "d4b1b568-a457-47f1-bb46-5a6e51a78c37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.8631 - loss: 0.7093\n",
            "Test Accuracy: 0.8636\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load dataset from Kaggle CSV files\n",
        "train_data = pd.read_csv(\"/root/.cache/kagglehub/datasets/crawford/emnist/versions/3/emnist-balanced-train.csv\")\n",
        "test_data = pd.read_csv(\"/root/.cache/kagglehub/datasets/crawford/emnist/versions/3/emnist-balanced-test.csv\")\n",
        "\n",
        "# Extract labels and pixel values\n",
        "train_labels = train_data.iloc[:, 0].values\n",
        "test_labels = test_data.iloc[:, 0].values\n",
        "train_images = train_data.iloc[:, 1:].values\n",
        "test_images = test_data.iloc[:, 1:].values\n",
        "\n",
        "# Normalize pixel values\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "num_classes = len(np.unique(train_labels))  # Should be 47 for EMNIST Balanced\n",
        "train_labels = to_categorical(train_labels, num_classes)\n",
        "test_labels = to_categorical(test_labels, num_classes)\n",
        "\n",
        "# Define Ant Colony Optimization (ACO) for Feature Selection\n",
        "def aco_feature_selection(num_ants=10, iterations=5, num_features=784, alpha=1, beta=1, evaporation=0.5):\n",
        "    pheromone = np.ones(num_features)  # Initialize pheromone levels for all features\n",
        "    best_features = None\n",
        "    best_accuracy = 0\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        for ant in range(num_ants):\n",
        "            selected_features = np.random.choice(range(num_features), size=784, replace=False)\n",
        "\n",
        "\n",
        "            # Create new dataset with selected features\n",
        "            train_subset = train_images[:, selected_features]\n",
        "            test_subset = test_images[:, selected_features]\n",
        "\n",
        "            # Reshape for CNN compatibility\n",
        "            train_subset = train_subset.reshape(-1, 28, 28, 1)\n",
        "            test_subset = test_subset.reshape(-1, 28, 28, 1)\n",
        "\n",
        "            # Define CNN model\n",
        "            model = Sequential([\n",
        "                Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "                BatchNormalization(),\n",
        "                MaxPooling2D(2, 2),\n",
        "                Conv2D(64, (3, 3), activation='relu'),\n",
        "                BatchNormalization(),\n",
        "                MaxPooling2D(2, 2),\n",
        "                Flatten(),\n",
        "                Dense(256, activation='relu'),\n",
        "                Dropout(0.5),\n",
        "                Dense(num_classes, activation='softmax')\n",
        "            ])\n",
        "\n",
        "            model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                          loss='categorical_crossentropy',\n",
        "                          metrics=['accuracy'])\n",
        "\n",
        "            model.fit(train_subset, train_labels, epochs=3, batch_size=32, verbose=0)\n",
        "            _, accuracy = model.evaluate(test_subset, test_labels, verbose=0)\n",
        "\n",
        "            # Update pheromone levels\n",
        "            if accuracy > best_accuracy:\n",
        "                best_accuracy = accuracy\n",
        "                best_features = selected_features\n",
        "            pheromone[selected_features] *= (1 - evaporation) + accuracy  # Update pheromone levels\n",
        "\n",
        "    print(f'Best Feature Set Selected: {len(best_features)} features')\n",
        "    print(f'Best Accuracy: {best_accuracy}')\n",
        "    return best_features\n",
        "\n",
        "# Run ACO for feature selection\n",
        "best_features = aco_feature_selection()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1po-U8LCFhg4",
        "outputId": "c4b34e43-1ce5-4e83-c26b-f17808c71099"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Feature Set Selected: 784 features\n",
            "Best Accuracy: 0.7928613424301147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create and train the model\n",
        "model = create_model()\n",
        "\n"
      ],
      "metadata": {
        "id": "ImkRtPnAiVGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import random\n",
        "\n",
        "# Load dataset from Kaggle CSV files\n",
        "train_data = pd.read_csv(\"/root/.cache/kagglehub/datasets/crawford/emnist/versions/3/emnist-balanced-train.csv\")\n",
        "test_data = pd.read_csv(\"/root/.cache/kagglehub/datasets/crawford/emnist/versions/3/emnist-balanced-test.csv\")\n",
        "\n",
        "# Extract labels and pixel values\n",
        "train_labels = train_data.iloc[:, 0].values\n",
        "test_labels = test_data.iloc[:, 0].values\n",
        "train_images = train_data.iloc[:, 1:].values\n",
        "test_images = test_data.iloc[:, 1:].values\n",
        "\n",
        "# Normalize pixel values\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Reshape images to (28, 28, 1)\n",
        "train_images = train_images.reshape(-1, 28, 28, 1)\n",
        "test_images = test_images.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "num_classes = len(np.unique(train_labels))  # Should be 47 for EMNIST Balanced\n",
        "train_labels = to_categorical(train_labels, num_classes)\n",
        "test_labels = to_categorical(test_labels, num_classes)\n",
        "\n",
        "# Define Bee Algorithm for CNN Architecture Optimization\n",
        "def bee_algorithm(num_bees=10, iterations=5):\n",
        "    best_model = None\n",
        "    best_accuracy = 0\n",
        "    best_hyperparams = {}\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        for bee in range(num_bees):\n",
        "            # Randomly choose hyperparameters\n",
        "            num_filters = np.random.choice([32, 64, 128])\n",
        "            dropout_rate = np.random.uniform(0.3, 0.6)\n",
        "            learning_rate = np.random.uniform(0.0001, 0.01)\n",
        "\n",
        "            # Define CNN model\n",
        "            model = Sequential([\n",
        "                Conv2D(num_filters, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "                BatchNormalization(),\n",
        "                MaxPooling2D(2, 2),\n",
        "                Conv2D(64, (3, 3), activation='relu'),\n",
        "                BatchNormalization(),\n",
        "                MaxPooling2D(2, 2),\n",
        "                Flatten(),\n",
        "                Dense(256, activation='relu'),\n",
        "                Dropout(dropout_rate),\n",
        "                Dense(num_classes, activation='softmax')\n",
        "            ])\n",
        "\n",
        "            model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                          loss='categorical_crossentropy',\n",
        "                          metrics=['accuracy'])\n",
        "\n",
        "            model.fit(train_images, train_labels, epochs=3, batch_size=32, verbose=0)\n",
        "            _, accuracy = model.evaluate(test_images, test_labels, verbose=0)\n",
        "\n",
        "            if accuracy > best_accuracy:\n",
        "                best_accuracy = accuracy\n",
        "                best_model = model\n",
        "                best_hyperparams = {'filters': num_filters, 'dropout': dropout_rate, 'learning_rate': learning_rate}\n",
        "\n",
        "    print(f'Best Hyperparameters: {best_hyperparams}')\n",
        "    print(f'Best Accuracy: {best_accuracy}')\n",
        "    return best_model, best_hyperparams\n",
        "\n",
        "# Run Bee Algorithm for CNN optimization\n",
        "best_model, best_hyperparams = bee_algorithm()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "OwBqqqg7Fi2p",
        "outputId": "aa28f99f-6d5c-4c05-b880-f8916a0ee29f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-b9cb47f72bc7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;31m# Run Bee Algorithm for CNN optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_hyperparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbee_algorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-b9cb47f72bc7>\u001b[0m in \u001b[0;36mbee_algorithm\u001b[0;34m(num_bees, iterations)\u001b[0m\n\u001b[1;32m     61\u001b[0m                           metrics=['accuracy'])\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EDd5_MN_FsAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import random\n",
        "\n",
        "# Load dataset from Kaggle CSV files\n",
        "train_data = pd.read_csv(\"/root/.cache/kagglehub/datasets/crawford/emnist/versions/3/emnist-balanced-train.csv\")\n",
        "test_data = pd.read_csv(\"/root/.cache/kagglehub/datasets/crawford/emnist/versions/3/emnist-balanced-test.csv\")\n",
        "\n",
        "# Extract labels and pixel values\n",
        "train_labels = train_data.iloc[:, 0].values\n",
        "test_labels = test_data.iloc[:, 0].values\n",
        "train_images = train_data.iloc[:, 1:].values\n",
        "test_images = test_data.iloc[:, 1:].values\n",
        "\n",
        "# Normalize pixel values\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Reshape images to (28, 28, 1)\n",
        "train_images = train_images.reshape(-1, 28, 28, 1)\n",
        "test_images = test_images.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "num_classes = len(np.unique(train_labels))  # Should be 47 for EMNIST Balanced\n",
        "train_labels = to_categorical(train_labels, num_classes)\n",
        "test_labels = to_categorical(test_labels, num_classes)\n",
        "\n",
        "# Define Genetic Algorithm (GA) for Hyperparameter Optimization\n",
        "def create_model(params):\n",
        "    model = Sequential([\n",
        "        Conv2D(params['filters'], (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(params['dropout']),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params['learning_rate']),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Genetic Algorithm for Optimization\n",
        "def genetic_algorithm(pop_size=10, generations=5, mutation_rate=0.2):\n",
        "    population = [{'filters': random.choice([32, 64, 128]),\n",
        "                   'dropout': random.uniform(0.3, 0.6),\n",
        "                   'learning_rate': random.uniform(0.0001, 0.01)} for _ in range(pop_size)]\n",
        "\n",
        "    for generation in range(generations):\n",
        "        scores = []\n",
        "        for individual in population:\n",
        "            model = create_model(individual)\n",
        "            model.fit(train_images, train_labels, epochs=3, batch_size=32, verbose=0)\n",
        "            _, accuracy = model.evaluate(test_images, test_labels, verbose=0)\n",
        "            scores.append((individual, accuracy))\n",
        "\n",
        "        scores.sort(key=lambda x: x[1], reverse=True)\n",
        "        print(f'Generation {generation + 1} - Best Accuracy: {scores[0][1]}')\n",
        "\n",
        "        # Select top individuals\n",
        "        new_population = [x[0] for x in scores[:pop_size // 2]]\n",
        "\n",
        "        # Crossover\n",
        "        for _ in range(pop_size // 2):\n",
        "            parent1, parent2 = random.sample(new_population, 2)\n",
        "            child = {key: random.choice([parent1[key], parent2[key]]) for key in parent1}\n",
        "\n",
        "            # Mutation\n",
        "            if random.random() < mutation_rate:\n",
        "                child['filters'] = random.choice([32, 64, 128])\n",
        "                child['dropout'] = random.uniform(0.3, 0.6)\n",
        "                child['learning_rate'] = random.uniform(0.0001, 0.01)\n",
        "\n",
        "            new_population.append(child)\n",
        "\n",
        "        population = new_population\n",
        "\n",
        "    best_params = scores[0][0]\n",
        "    print(f'Best Hyperparameters: {best_params}')\n",
        "    return best_params\n",
        "\n",
        "# Run GA optimization\n",
        "best_params = genetic_algorithm()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-7d6hMnKur2",
        "outputId": "26bdb5c0-50f6-4cf4-f1c7-567ba978ff4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation 1 - Best Accuracy: 0.8398318886756897\n",
            "Generation 2 - Best Accuracy: 0.8608436584472656\n",
            "Generation 3 - Best Accuracy: 0.8623862862586975\n",
            "Generation 4 - Best Accuracy: 0.8621734976768494\n",
            "Generation 5 - Best Accuracy: 0.8628118634223938\n",
            "Best Hyperparameters: {'filters': 64, 'dropout': 0.38660366275446795, 'learning_rate': 0.0002248029413911395}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emnist.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_947yJI00XWu",
        "outputId": "d949daf2-26cb-4a58-bae0-f6c603a515bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(112799, 785)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emnist_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svJT2rod0olb",
        "outputId": "feb526b4-5bfc-446f-beb5-1fb32584b27f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18799, 785)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import random\n",
        "\n",
        "# Load dataset from Kaggle CSV files\n",
        "train_data = pd.read_csv(\"/root/.cache/kagglehub/datasets/crawford/emnist/versions/3/emnist-balanced-train.csv\")\n",
        "test_data = pd.read_csv(\"/root/.cache/kagglehub/datasets/crawford/emnist/versions/3/emnist-balanced-test.csv\")\n",
        "\n",
        "# Extract labels and pixel values\n",
        "train_labels = train_data.iloc[:, 0].values\n",
        "test_labels = test_data.iloc[:, 0].values\n",
        "train_images = train_data.iloc[:, 1:].values\n",
        "test_images = test_data.iloc[:, 1:].values\n",
        "\n",
        "# Normalize pixel values\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Reshape images to (28, 28, 1)\n",
        "train_images = train_images.reshape(-1, 28, 28, 1)\n",
        "test_images = test_images.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "num_classes = len(np.unique(train_labels))  # Should be 47 for EMNIST Balanced\n",
        "train_labels = to_categorical(train_labels, num_classes)\n",
        "test_labels = to_categorical(test_labels, num_classes)\n",
        "\n",
        "# Define Genetic Algorithm (GA) for Hyperparameter Optimization\n",
        "def create_model():\n",
        "    model = Sequential([\n",
        "        Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(0.38660366275446795),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002248029413911395),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "68Kz09di0uET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = create_model()\n",
        "best_model.fit(train_images, train_labels, epochs=15, batch_size=32, validation_data=(train_images, train_labels))\n",
        "\n",
        "# Evaluate final model\n",
        "test_loss, test_acc = best_model.evaluate(test_images, test_labels)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9Miexzyca8i",
        "outputId": "88795cc4-8fa3-4bd6-a0e2-7220b729b1a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 7ms/step - accuracy: 0.6218 - loss: 1.3458 - val_accuracy: 0.8671 - val_loss: 0.4001\n",
            "Epoch 2/15\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step - accuracy: 0.8248 - loss: 0.5294 - val_accuracy: 0.8846 - val_loss: 0.3286\n",
            "Epoch 3/15\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 6ms/step - accuracy: 0.8541 - loss: 0.4268 - val_accuracy: 0.9021 - val_loss: 0.2690\n",
            "Epoch 4/15\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.8690 - loss: 0.3669 - val_accuracy: 0.9163 - val_loss: 0.2324\n",
            "Epoch 5/15\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step - accuracy: 0.8859 - loss: 0.3167 - val_accuracy: 0.9226 - val_loss: 0.2085\n",
            "Epoch 6/15\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 6ms/step - accuracy: 0.8944 - loss: 0.2879 - val_accuracy: 0.9330 - val_loss: 0.1797\n",
            "Epoch 7/15\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step - accuracy: 0.9032 - loss: 0.2575 - val_accuracy: 0.9404 - val_loss: 0.1639\n",
            "Epoch 8/15\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 6ms/step - accuracy: 0.9095 - loss: 0.2381 - val_accuracy: 0.9452 - val_loss: 0.1489\n",
            "Epoch 9/15\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 6ms/step - accuracy: 0.9173 - loss: 0.2160 - val_accuracy: 0.9526 - val_loss: 0.1279\n",
            "Epoch 10/15\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - accuracy: 0.9247 - loss: 0.2004 - val_accuracy: 0.9582 - val_loss: 0.1127\n",
            "Epoch 11/15\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - accuracy: 0.9279 - loss: 0.1843 - val_accuracy: 0.9610 - val_loss: 0.1084\n",
            "Epoch 12/15\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9334 - loss: 0.1714 - val_accuracy: 0.9658 - val_loss: 0.0946\n",
            "Epoch 13/15\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - accuracy: 0.9364 - loss: 0.1612 - val_accuracy: 0.9677 - val_loss: 0.0872\n",
            "Epoch 14/15\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 6ms/step - accuracy: 0.9407 - loss: 0.1521 - val_accuracy: 0.9707 - val_loss: 0.0811\n",
            "Epoch 15/15\n",
            "\u001b[1m3525/3525\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9445 - loss: 0.1429 - val_accuracy: 0.9745 - val_loss: 0.0710\n",
            "\u001b[1m588/588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8672 - loss: 0.5569\n",
            "Test Accuracy: 0.8679\n"
          ]
        }
      ]
    }
  ]
}